{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  \n",
    "import nltk  \n",
    "nltk.download('stopwords') \n",
    "\n",
    "from nltk.corpus import stopwords  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/Mridul/Documents/Courses/Topics Data mining/Project/pm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Emotion', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0].values  \n",
    "\n",
    "print(X)\n",
    "\n",
    "# X is an array of tweets\n",
    "X.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.iloc[:,2].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in range(0, len(X)):  \n",
    "    # Remove all the special characters\n",
    "    processed_tweet = re.sub(r'\\W', ' ', str(X[tweet]))\n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    "    # Remove single characters from the start\n",
    "    processed_tweet = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_tweet)  \n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n",
    " \n",
    "     # Removing prefixed 'b'\n",
    "    processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    processed_tweet = processed_tweet.lower()\n",
    "\n",
    "    processed_tweets.append(processed_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_tweets is a list with text values\n",
    "for i in range(len(processed_tweets)):\n",
    " print(processed_tweets[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = processed_tweets[1].split()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=df.columns\n",
    "print(cols)\n",
    "#cols[0] prints a sring value at index 0 in cols\n",
    "cols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ColumnName, DataType, MissingValues')\n",
    "for i in cols:\n",
    "    print(i, ',', df[i].dtype,',',df[i].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "##import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting stopwords in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming all the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_tweets = []\n",
    "for tweet in processed_tweets:\n",
    "    stem_tweet = []\n",
    "    tweet = tweet.split(' ')\n",
    "    #print('splitted tweett : ', tweet, end = '\\n')\n",
    "    for word in tweet:\n",
    "        if word not in stopwords_set:\n",
    "            stem_tweet.append(ps.stem(word))\n",
    "#     print(stem_tweet)\n",
    "    stemmed_tweets.append(' '.join(stem_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word Tokeniztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(processed_tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    print(w, \" : \", ps.stem(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "tfidfconverter = TfidfVectorizer(max_features=2000 , min_df=5, max_df=0.7)  \n",
    "X = tfidfconverter.fit_transform(stemmed_tweets).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidfconverter.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidfconverter.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X)\n",
    "X.dtype\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame(X, columns = feature_names) #, headers=feature_names)\n",
    "\n",
    "new.head()\n",
    "\n",
    "#new.to_csv(\"C:/Users/Parth Kaushik/Desktop/3rd Semester/Data Mining/DM project explore/DMP Explore V2/filenaughty.csv\", header=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new.to_csv(\"C:/Users/Parth Kaushik/Desktop/3rd Semester/Data Mining/DM project explore/DMP Explore V2/filenaughty1.csv\", header=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier = RandomForestClassifier(n_estimators=100, random_state=1)  \n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2\n",
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    " \n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  \n",
    "print(accuracy_score(y_test, predictions))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Through new file with column\n",
    "df1=pd.read_csv('C:/Users/Mridul/Documents/Courses/Topics Data mining/Project/filenew4.csv')\n",
    "df1.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Brand'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['Brand'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df['Emotion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Brand'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Emotion'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL BUILDING \n",
    "\n",
    "1. KNN\n",
    "2. Naive Bayes\n",
    "3. Decison Tree\n",
    "4. SVM\n",
    "5  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=df1.columns\n",
    "# print out and display dataframe as tables in HTML\n",
    "display(HTML(df1.head(5).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ColumnName, DataType, MissingValues')\n",
    "for i in cols:\n",
    "    print(i, ',', df1[i].dtype,',',df1[i].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1_knn =df1.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label Encoding\n",
    "from sklearn import preprocessing\n",
    "y = df1_knn['Emotion'] # define label as nominal values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y_encoded = le.transform(y) # encode nominal labels to integers #####################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dummies = pd.get_dummies(df1_knn['Brand'])\n",
    "df1_knn = df1.join(df1_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_knn = df1_knn.drop('Brand', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_knn['Emotion'] = y_encoded\n",
    "x_k = df1_knn.drop('Emotion', 1)\n",
    "y_k = df1_knn['Emotion']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running model using nfold cv\n",
    "from sklearn import neighbors\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for k in range(1, 10, 2): \n",
    "    clf=neighbors.KNeighborsClassifier(k, weights='uniform')\n",
    "    # this means for every k value in the loop, accuracy is calculated using clf model(on X and Y vars) with cv approach\n",
    "    # for every k value, mean of accuracy for 5 different arrangements of train and test data (CV) is calculated   \n",
    "    acc=cross_val_score(clf, x_k, y_k, cv=5, scoring='accuracy').mean()   \n",
    "    print('K =', k, ', Accuracy: ',acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_NB=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_NB.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_NB['Tweet'] = pd.cut(df1_NB['Tweet'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('filenew4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb['Brand'] = a\n",
    "df_nb['Emotion'] = b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementong N B test\n",
    "for i in range(0,len(df_nb[0:1005])):\n",
    "    df_nb[df_nb.columns[i]]= pd.cut(df_nb[df_nb.columns[i]],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##label encoding\n",
    "y = df_nb['Emotion']\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "# encode nominal label to integer form\n",
    "y_encoded = le.transform(y) \n",
    "\n",
    "#transforming the label type to numerical \n",
    "df_nb['Emotion'] = y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nb = pd.get_dummies(df_nb.drop('Emotion', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nb = df_nb['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(x_nb.head(5).to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing naive bayess model by N-fold evaluation ###############\n",
    "clf = GaussianNB()\n",
    "acc=cross_val_score(clf, x_nb, y_nb, cv=5, scoring='accuracy').mean()\n",
    "print(\"Accuracy by N-fold Cross Validation:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest and Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by N-fold cross validation\n",
    "acc=cross_val_score(clf, x_nb, y_nb, cv=10, scoring='accuracy').mean()\n",
    "print(\"Tree Accuracy by N-fold Cross Validation:\",acc)\n",
    "\n",
    "# Example of randomForest = bagging method of decision trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DT\n",
    "tree = DecisionTreeClassifier()\n",
    "acc=cross_val_score(tree, x_nb, y_nb, cv=5, scoring='accuracy').mean()\n",
    "print(\"Dec tree Accuracy by N-fold Cross Validation:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "tree = DecisionTreeClassifier()\n",
    "bag = BaggingClassifier(tree, n_estimators=50, max_samples=0.8, random_state=1)\n",
    "acc=cross_val_score(bag, x_nb, y_nb, cv=5, scoring='accuracy').mean()\n",
    "print(\"RandomForest Accuracy by N-fold Cross Validation:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFUSION MATRIX\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(clf, x_k, y_k, cv=3)\n",
    "\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy by Hold-out Eval:\",accuracy_score(y_pred,y_k))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_k)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "cnf_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "classification_report(y_k, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Through new file with column\n",
    "df1=pd.read_csv('C:/Users/Mridul/Documents/Courses/Topics Data mining/Project/filenew4.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Brand'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#dropping the unwanted column called Unnamedfrom start\n",
    "df1 = df1.drop(df1.columns[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding Brand column\n",
    "a = df['Brand'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding Emotion column\n",
    "b = df['Emotion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Brand'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Emotion'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Brand'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAYING THE DATA SET\n",
    "display(HTML(df1.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SELECTION\n",
    "####### Feature Selection using Wrapper Model\n",
    "# We are using decision trees to select features based on their impurity\n",
    "df1  =pd.read_csv('C:/Users/Mridul/Documents/Courses/Topics Data mining/Project/filenew4.csv')\n",
    "df1 = df1.drop(df1.columns[0], axis = 1)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "\n",
    "a = df['Brand'].tolist()\n",
    "df1['Brand'] = a\n",
    "\n",
    "b = df['Emotion'].tolist()\n",
    "df1['Emotion'] = b\n",
    "\n",
    "df_fs = df1.copy(deep = True)\n",
    "\n",
    "display(HTML(df_fs.head(10).to_html()))\n",
    "\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "x_fs = df_fs.drop('Emotion', 1)\n",
    "x_dummies = pd.get_dummies(x_fs['Brand'])\n",
    "\n",
    "x_fs = x_fs.join(x_dummies)\n",
    "x_fs = x_fs.drop('Brand',1)\n",
    "\n",
    "#x_fs = df_fs.drop('Emotion', 1)\n",
    "\n",
    "#label encoding\n",
    "y = df_fs['Emotion'] # define label as nominal values\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "#encode nominal to numerical\n",
    "y_encoded = le.transform(y) \n",
    "\n",
    "df_fs['Emotion'] = y_encoded\n",
    "\n",
    "y_fs = df_fs['Emotion']\n",
    "\n",
    "display(HTML(x_fs.head(10).to_html()))\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x_fs, y_fs)\n",
    "\n",
    "values=model.feature_importances_.tolist()\n",
    "keys=x_fs.columns.tolist()\n",
    "d = dict(zip(keys, values))\n",
    "\n",
    "# sort pairs by values descending\n",
    "s = [(k, d[k]) for k in sorted(d, key=d.get, reverse=True)]\n",
    "\n",
    "\n",
    "print('\\nSelected features by Wrapper model (classification):\\n')\n",
    "for k, v in s:\n",
    "    print(k,'\\t',v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the features with importance\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#priting the dictionary \n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding features and respective importance to a new data frame \n",
    "trial_df = pd.DataFrame(data = s, columns = ['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting important features with importance > 0.0003501658827884306\n",
    "is_imp = trial_df['importance'] >= 0.00017688060945493343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df_imp = trial_df[is_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting important features in a array called imp_features \n",
    "imp_features = trial_df_imp['feature'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imp_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing important features\n",
    "print(x_fs.ix[:,imp_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new data frame with important features selected in feature selecion that is important keywords only\n",
    "final_set = x_fs[imp_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ADDING THE OUTPUT OF THE CLUSTERS TO THE INPUT OF THE SUPERVISED LEARNING TECHNIQUE #####\n",
    "\n",
    "\n",
    "# RUNNING KMEANS CLUSETRS\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans=KMeans(n_clusters=16)\n",
    "kmeans.fit(final_set)\n",
    "y_pred=kmeans.predict(final_set)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the clusters to a array\n",
    "clusters = kmeans.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_set['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding label Emotion to final set \n",
    "final_set['Emotion'] = df1['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL BUILDING \n",
    "\n",
    "#1. KNN\n",
    "#2. Naive Bayes\n",
    "#3. Decison Tree\n",
    "#4. SVM\n",
    "#5  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ColumnName, DataType, MissingValues')\n",
    "for i in cols:\n",
    "    print(i, ',', final_set[i].dtype,',',final_set[i].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_set = final_set.drop('clusters',axis=1)\n",
    "df1_knn =final_set.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(HTML(df1_knn.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label Encoding\n",
    "from sklearn import preprocessing\n",
    "y = df1_knn['Emotion'] # define label as nominal values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y_encoded = le.transform(y) # encode nominal labels to integers #####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(df1_knn.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_knn['Emotion'] = y_encoded\n",
    "x_k = df1_knn.drop('Emotion', 1)\n",
    "y_k = df1_knn['Emotion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNNING MODEL USING NFOLD CV NOW AFTER FEATURE SELECTION AND CLUSTERING AS A INPUT\n",
    "from sklearn import neighbors\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for k in range(1, 10, 2): \n",
    "    clf=neighbors.KNeighborsClassifier(k, weights='uniform')\n",
    "    # this means for every k value in the loop, accuracy is calculated using clf model(on X and Y vars) with cv approach\n",
    "    # for every k value, mean of accuracy for 5 different arrangements of train and test data (CV) is calculated   \n",
    "    acc=cross_val_score(clf, x_k, y_k, cv=5, scoring='accuracy').mean()   \n",
    "    print('K =', k, ', Accuracy: ',acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb = final_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementong N B test\n",
    "for i in range(0,len(df_nb[0:712])):\n",
    "    df_nb[df_nb.columns[i]]= pd.cut(df_nb[df_nb.columns[i]],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##label encoding\n",
    "y = df_nb['Emotion']\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "# encode nominal label to integer form\n",
    "y_encoded = le.transform(y) \n",
    "\n",
    "#transforming the label type to numerical \n",
    "df_nb['Emotion'] = y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nb = pd.get_dummies(df_nb.drop('Emotion', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nb = df_nb['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(x_nb.head(5).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing naive bayess model by N-fold evaluation ###############\n",
    "clf = GaussianNB()\n",
    "acc=cross_val_score(clf, x_nb, y_nb, cv=5, scoring='accuracy').mean()\n",
    "print(\"Accuracy by N-fold Cross Validation:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest and Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by N-fold cross validation\n",
    "acc=cross_val_score(clf, x_nb, y_nb, cv=10, scoring='accuracy').mean()\n",
    "print(\"Tree Accuracy by N-fold Cross Validation:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Compound score and Emotion using NLTK library from Tweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd \n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "#from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "from sklearn import metrics\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from TextBlob we calculate sentiment in the  form of (polarity, subjectivity) polarity - emotion- [-1,1]\n",
    "# subjectivity - 0(factual info), 1(opinion)- [0,1]\n",
    "def calculate_sentiment(Clean_text):\n",
    "    return TextBlob(Clean_text).sentiment\n",
    "\n",
    "analyser = SIA()\n",
    "\n",
    "#Defining the function for calculating polarity_scores\n",
    "def calculate_sentiment_analyser(Clean_text):    \n",
    "    return analyser.polarity_scores(Clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.DataFrame(processed_tweets, columns = ['Clean_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Values of polarity, compound score and sentiment corresponding to each tweet in the data frame using following algo \n",
    "dfn['sentiment']=dfn.Clean_text.apply(calculate_sentiment)\n",
    "dfn['sentiment_analyser']=dfn.Clean_text.apply(calculate_sentiment_analyser)\n",
    "\n",
    "\n",
    "s = pd.DataFrame(index = range(0,len(dfn)),columns= ['compound_score','compound_score_sentiment'])\n",
    "\n",
    "for i in range(0,len(dfn)): \n",
    "  s['compound_score'][i] = dfn['sentiment_analyser'][i]['compound']\n",
    "  \n",
    "  if (dfn['sentiment_analyser'][i]['compound'] <= -0.05):\n",
    "    s['compound_score_sentiment'][i] = 'Negative'    \n",
    "  if (dfn['sentiment_analyser'][i]['compound'] >= 0.05):\n",
    "    s['compound_score_sentiment'][i] = 'Positive'\n",
    "  if ((dfn['sentiment_analyser'][i]['compound'] >= -0.05) & (dfn['sentiment_analyser'][i]['compound'] <= 0.05)):\n",
    "    s['compound_score_sentiment'][i] = 'Neutral'\n",
    "    \n",
    "dfn['compound_score'] = s['compound_score']\n",
    "dfn['compound_score_sentiment'] = s['compound_score_sentiment']\n",
    "dfn.head(4)\n",
    "\n",
    "# The neg neu and pos shows how much portion of text is negative, neutral and positive amd compund score is average of these\n",
    "\n",
    "#stats about Emotion \n",
    "dfn['compound_score_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Cluster through new file with column\n",
    "df1=pd.read_csv('C:/Users/Mridul/Documents/Courses/Topics Data mining/Project/CodeTfidf2.csv')\n",
    "df1.info()\n",
    "\n",
    "\n",
    "df1.head()\n",
    "\n",
    "#df1.iloc[:, 0:50]\n",
    "\n",
    "len(df1[0:10])\n",
    "df1[df1.columns[1]]\n",
    "\n",
    "#implementong N B test\n",
    "#for i in range(0,len(df1[0:100])):\n",
    " #  df1[df1.columns[i]]= pd.cut(df1[df1.columns[i]],2)\n",
    "    \n",
    "    \n",
    "\n",
    "df1.head()\n",
    "\n",
    "df1[df1.columns[0]]\n",
    "\n",
    "#df_d = pd.cut( df1[df1.columns[0:1005]], 2)\n",
    "\n",
    "#df_d.head()\n",
    "\n",
    "#df_d.to_csv(\"C:/Users/Mridul/Documents/Courses/Topics Data mining/Project/check.csv\", header = True)\n",
    "\n",
    "df1.describe()\n",
    "\n",
    "df1 = df1.join(df['Brand'])\n",
    "\n",
    "df1 = df1.join(df['Emotion'])\n",
    "\n",
    "\n",
    "\n",
    "len(df1)\n",
    "\n",
    "df1.describe()\n",
    "\n",
    "df1.columns\n",
    "\n",
    "df1 = df1.drop(df1.columns[0], axis= 1)\n",
    "\n",
    "df_m =  pd.get_dummies(df1['Brand'])\n",
    "\n",
    "#df_m.head()\n",
    "df1 = df1.join(df_m)\n",
    "\n",
    "df1 = df1.drop('Brand', axis = 1)\n",
    "\n",
    "display(HTML(df1.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Emotion'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Emotion'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### CLUSTERING ##############\n",
    "################### CLUSTERING ##############\n",
    "################### CLUSTERING ##############\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "##################################### Finding Optimal Clusters\n",
    "def find_optimal_clusters(data, max_k):\n",
    "    iters = range(2, max_k+1, 2)\n",
    "    \n",
    "    sse = []\n",
    "    for k in iters:\n",
    "        sse.append(MiniBatchKMeans(n_clusters=k, init_size=1024, batch_size=2048, random_state=20).fit(data).inertia_)\n",
    "        print('Fit {} clusters'.format(k))\n",
    "        \n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    ax.plot(iters, sse, marker='o')\n",
    "    ax.set_xlabel('Cluster Centers')\n",
    "    ax.set_xticks(iters)\n",
    "    ax.set_xticklabels(iters)\n",
    "    ax.set_ylabel('SSE')\n",
    "    ax.set_title('SSE by Cluster Center Plot')\n",
    "    \n",
    "find_optimal_clusters(X, 20)\n",
    "\n",
    "#Applying Kmeans clustering on data using 16 clusters\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans=KMeans(n_clusters=16)\n",
    "kmeans.fit(df1.drop('Emotion', axis = 1))\n",
    "y_pred=kmeans.predict(df1.drop('Emotion', axis = 1))\n",
    "\n",
    "#y_pred\n",
    "\n",
    "clusters = kmeans.labels_.tolist()\n",
    "\n",
    "#clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHecking for total values in clusters \n",
    "import collections\n",
    "cnt = collections.Counter()\n",
    "cnt = 0\n",
    "for i in y_pred:\n",
    "    print(i)\n",
    "    cnt+=1\n",
    "    \n",
    "print('counter value: ',cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding clusters in a data frame corresponding to tweets\n",
    "tweets = {'Tweet': processed_tweets, 'Cluster': clusters}\n",
    "frame = pd.DataFrame(tweets, index = [clusters])\n",
    "frame\n",
    "\n",
    "df['Brand'].isnull().any()\n",
    "len(df['Brand'])\n",
    "\n",
    "len(frame)\n",
    "\n",
    "\n",
    "\n",
    "#frame.to_csv(\"C:/Users/Mridul/Documents/Courses/Topics Data mining/Project/cluster_detail_final.csv\")\n",
    "\n",
    "cluster_d = pd.read_csv(\"C:/Users/Mridul/Documents/Courses/Topics Data mining/Project/cluster_detail_final.csv\")\n",
    "\n",
    "cluster_d = cluster_d.join(dfn['compound_score'])\n",
    "\n",
    "#Displaying the tweets as well as clusters with Emotion and Brand\n",
    "display(HTML(cluster_d.head(10).to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats for clusters\n",
    "for i in range(0, 15):\n",
    "    grp = cluster_d.loc[(cluster_d.Cluster == i)]\n",
    "    print(\"\")\n",
    "    print(\"cluster: \", i, end = \"\\n\")\n",
    "    print(grp['Emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TOP CLUSTER KEYWORDS\n",
    "def get_top_keywords(data, clusters, labels, n_terms):\n",
    "    df = pd.DataFrame(data).groupby(clusters).mean()\n",
    "    \n",
    "    for i,r in df.iterrows():\n",
    "        print('\\nCluster {}'.format(i))\n",
    "        print(','.join([labels[t] for t in np.argsort(r)[-n_terms:]]))\n",
    "            \n",
    "get_top_keywords(X, y_pred, tfidfconverter.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.join(dfn['compound_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster for Apple brand: Keyword_ipad2 vs Compound_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#company apple\n",
    "Apple = df1.loc[(df1.Apple== 1)]\n",
    "\n",
    "len(Apple)\n",
    "\n",
    "#len(Apple)\n",
    "\n",
    "len(df1.loc[(df1.Apple== 1)])\n",
    "\n",
    "Apple['Apple']\n",
    "\n",
    "\n",
    "\n",
    "# clustering for term freqs for those tweets which have opinion aout ipad2 and the respective compound_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans=KMeans(n_clusters=16)\n",
    "kmeans.fit(Apple.drop('Emotion', axis = 1))\n",
    "y_pred2=kmeans.predict(Apple.drop('Emotion', axis = 1))\n",
    "\n",
    "plt.scatter(Apple['compound_score'],Apple['ipad2'],c=y_pred2,cmap='viridis')\n",
    "plt.xlabel('Compound_Score')\n",
    "plt.ylabel('Keyword_ipad2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster for Apple brand: Keyword_app vs Compound_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering for term freqs for those tweets which have opinion aout app and the respective compound_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans=KMeans(n_clusters=16)\n",
    "kmeans.fit(Apple.drop('Emotion', axis = 1))\n",
    "y_pred2=kmeans.predict(Apple.drop('Emotion', axis = 1))\n",
    "\n",
    "plt.scatter(Apple['compound_score'],Apple['app'],c=y_pred2,cmap='viridis')\n",
    "plt.xlabel('Compound_Score')\n",
    "plt.ylabel('Keyword_app')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster for Apple brand: Keyword_video vs Compound_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering for term freqs for those tweets which have opinion aout video and the respective compound_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans=KMeans(n_clusters=16)\n",
    "kmeans.fit(Apple.drop('Emotion', axis = 1))\n",
    "y_pred2=kmeans.predict(Apple.drop('Emotion', axis = 1))\n",
    "\n",
    "plt.scatter(Apple['compound_score'],Apple['video'],c=y_pred2,cmap='viridis')\n",
    "plt.xlabel('Compound_Score')\n",
    "plt.ylabel('Keyword_video')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster for Google brand: Keyword_look vs Compound_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google = df1.loc[(df1.Google== 1)]\n",
    "\n",
    "len(Google)\n",
    "\n",
    "# clustering for compound score against term freqs for those tweets which have opinion about look \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans=KMeans(n_clusters=14)\n",
    "kmeans.fit(Google.drop('Emotion', axis = 1))\n",
    "y_pred4=kmeans.predict(Google.drop('Emotion', axis = 1))\n",
    "\n",
    "plt.scatter(Google['compound_score'],Google['look'],c=y_pred4,cmap='viridis')\n",
    "plt.xlabel('Compound_Score')\n",
    "plt.ylabel('Keyword_look')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster for Google brand: Keyword_network vs Compound_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering for compound score against term freqs for those tweets which have opinion about network  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans=KMeans(n_clusters=14)\n",
    "kmeans.fit(Google.drop('Emotion', axis = 1))\n",
    "y_pred4=kmeans.predict(Google.drop('Emotion', axis = 1))\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(Google['compound_score'],Google['network'],c=y_pred4,cmap='viridis')\n",
    "plt.xlabel('Compound_Score')\n",
    "plt.ylabel('Keyword_network')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "\n",
    "# clustering Apple products against emotion = LOOKS FINE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans=KMeans(n_clusters=16)\n",
    "kmeans.fit(Apple.drop('Emotion', axis = 1))\n",
    "y_pred3=kmeans.predict(Apple.drop('Emotion', axis = 1))\n",
    "\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
